{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ca5075-191d-4f60-8325-18dceb61868f",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e850783-6a2a-4bd3-a6fb-7a921fa228fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0 -0.002268 -0.057392 -0.051938 -0.254064 -0.107042 -0.005746  0.053339   \n",
      "1 -0.095116  0.002254 -0.080440 -0.032033  0.325927 -0.089124  0.060066   \n",
      "2  0.171062 -0.006862 -0.092904  0.191909 -0.059166  0.084494  0.057149   \n",
      "3  0.091722 -0.023084 -0.170847  0.275267 -0.098605 -0.062822  0.026235   \n",
      "4  0.058596 -0.003751 -0.051466  0.243470  0.019038 -0.036104 -0.019322   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.155956  0.116585 -0.038332  ...   0.072443   0.059975  -0.076614   \n",
      "1  0.011424  0.037144 -0.126206  ...   0.060893  -0.161714  -0.016327   \n",
      "2 -0.057770  0.018334  0.042601  ...  -0.011123   0.010387   0.074528   \n",
      "3 -0.048630 -0.013406 -0.024388  ...  -0.104926   0.042281   0.022375   \n",
      "4 -0.011959 -0.054584 -0.058981  ...  -0.159260   0.032556  -0.005767   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0   0.036943   0.130576   0.409834  -0.142671   0.027263  -0.046064       0  \n",
      "1   0.029357   0.101992   0.217288  -0.190804   0.010403  -0.092698       0  \n",
      "2  -0.054416  -0.009584   0.244145  -0.002439   0.106801   0.046556       0  \n",
      "3   0.038976  -0.098919  -0.080987   0.140436   0.061884   0.038201       0  \n",
      "4   0.025254  -0.051693   0.056800  -0.031124   0.041619   0.015181       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n",
      "MSE: 5.508192793445987e+21\n",
      "RMSE: 74217200118.61124\n",
      "R²: -3.568389584980578e+21\n",
      "Standard Deviation of MSE: 5.894379626681844e+21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (assuming it's an Excel file as provided)\n",
    "df = pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "# Display basic info to ensure the data is loaded correctly\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "# Separate the features (embeddings) and target (output)\n",
    "X = df.drop(columns=['output']).values\n",
    "y = df['output'].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Grid Search (though linear regression doesn't have hyperparameters, this is for extensibility)\n",
    "grid_params = {}  # No hyperparameters for basic LinearRegression\n",
    "grid_search = GridSearchCV(model, grid_params, cv=kf, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# To speed up computation, let's reduce the dataset size by sampling 500 rows\n",
    "df_sample = df.sample(n=500, random_state=42)\n",
    "X_sample = df_sample.drop(columns=['output']).values\n",
    "y_sample = df_sample['output'].values\n",
    "\n",
    "# Normalize the sample data\n",
    "X_sample_scaled = scaler.fit_transform(X_sample)\n",
    "\n",
    "# Perform Grid Search and Cross Validation on the sample\n",
    "grid_search.fit(X_sample_scaled, y_sample)\n",
    "\n",
    "# Get the best estimator for the sample\n",
    "best_model_sample = grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation\n",
    "mse_scores_sample = cross_val_score(best_model_sample, X_sample_scaled, y_sample, cv=kf, scoring='neg_mean_squared_error')\n",
    "r2_scores_sample = cross_val_score(best_model_sample, X_sample_scaled, y_sample, cv=kf, scoring='r2')\n",
    "\n",
    "# Calculate metrics for the sample\n",
    "mse_sample = -mse_scores_sample.mean()  # MSE (convert from negative MSE)\n",
    "rmse_sample = np.sqrt(mse_sample)       # RMSE\n",
    "r2_sample = r2_scores_sample.mean()     # R²\n",
    "std_dev_sample = np.std(mse_scores_sample)  # Standard deviation of MSE\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"MSE: {mse_sample}\")\n",
    "print(f\"RMSE: {rmse_sample}\")\n",
    "print(f\"R²: {r2_sample}\")\n",
    "print(f\"Standard Deviation of MSE: {std_dev_sample}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af248e33-5c4e-4890-8aa6-8e2829abdb11",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1b2653-90e8-451e-a104-4265837e8f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0 -0.002268 -0.057392 -0.051938 -0.254064 -0.107042 -0.005746  0.053339   \n",
      "1 -0.095116  0.002254 -0.080440 -0.032033  0.325927 -0.089124  0.060066   \n",
      "2  0.171062 -0.006862 -0.092904  0.191909 -0.059166  0.084494  0.057149   \n",
      "3  0.091722 -0.023084 -0.170847  0.275267 -0.098605 -0.062822  0.026235   \n",
      "4  0.058596 -0.003751 -0.051466  0.243470  0.019038 -0.036104 -0.019322   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.155956  0.116585 -0.038332  ...   0.072443   0.059975  -0.076614   \n",
      "1  0.011424  0.037144 -0.126206  ...   0.060893  -0.161714  -0.016327   \n",
      "2 -0.057770  0.018334  0.042601  ...  -0.011123   0.010387   0.074528   \n",
      "3 -0.048630 -0.013406 -0.024388  ...  -0.104926   0.042281   0.022375   \n",
      "4 -0.011959 -0.054584 -0.058981  ...  -0.159260   0.032556  -0.005767   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0   0.036943   0.130576   0.409834  -0.142671   0.027263  -0.046064       0  \n",
      "1   0.029357   0.101992   0.217288  -0.190804   0.010403  -0.092698       0  \n",
      "2  -0.054416  -0.009584   0.244145  -0.002439   0.106801   0.046556       0  \n",
      "3   0.038976  -0.098919  -0.080987   0.140436   0.061884   0.038201       0  \n",
      "4   0.025254  -0.051693   0.056800  -0.031124   0.041619   0.015181       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n",
      "Best alpha (regularization strength): 100\n",
      "MSE: 0.8724219362885999\n",
      "RMSE: 0.934035297132073\n",
      "R²: 0.3820936183067435\n",
      "Standard Deviation of MSE: 0.1494857714761625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (assuming it's an Excel file as provided)\n",
    "df = pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "# Display basic info to ensure the data is loaded correctly\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "# Separate the features (embeddings) and target (output)\n",
    "X = df.drop(columns=['output']).values\n",
    "y = df['output'].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the Ridge Regression model\n",
    "model = Ridge()\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Grid Search for hyperparameter tuning (regularization strength 'alpha')\n",
    "grid_params = {'alpha': [0.01, 0.1, 1, 10, 100]}  # You can add more values if needed\n",
    "grid_search = GridSearchCV(model, grid_params, cv=kf, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# To speed up computation, let's reduce the dataset size by sampling 500 rows\n",
    "df_sample = df.sample(n=500, random_state=42)\n",
    "X_sample = df_sample.drop(columns=['output']).values\n",
    "y_sample = df_sample['output'].values\n",
    "\n",
    "# Normalize the sample data\n",
    "X_sample_scaled = scaler.fit_transform(X_sample)\n",
    "\n",
    "# Perform Grid Search and Cross Validation on the sample\n",
    "grid_search.fit(X_sample_scaled, y_sample)\n",
    "\n",
    "# Get the best estimator for the sample\n",
    "best_model_sample = grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation\n",
    "mse_scores_sample = cross_val_score(best_model_sample, X_sample_scaled, y_sample, cv=kf, scoring='neg_mean_squared_error')\n",
    "r2_scores_sample = cross_val_score(best_model_sample, X_sample_scaled, y_sample, cv=kf, scoring='r2')\n",
    "\n",
    "# Calculate metrics for the sample\n",
    "mse_sample = -mse_scores_sample.mean()  # MSE (convert from negative MSE)\n",
    "rmse_sample = np.sqrt(mse_sample)       # RMSE\n",
    "r2_sample = r2_scores_sample.mean()     # R²\n",
    "std_dev_sample = np.std(mse_scores_sample)  # Standard deviation of MSE\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Best alpha (regularization strength): {grid_search.best_params_['alpha']}\")\n",
    "print(f\"MSE: {mse_sample}\")\n",
    "print(f\"RMSE: {rmse_sample}\")\n",
    "print(f\"R²: {r2_sample}\")\n",
    "print(f\"Standard Deviation of MSE: {std_dev_sample}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cceb1b-f2c5-4845-932c-707032958ad4",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dac324-bc3a-4fa5-9a37-6e769a8c6c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0 -0.002268 -0.057392 -0.051938 -0.254064 -0.107042 -0.005746  0.053339   \n",
      "1 -0.095116  0.002254 -0.080440 -0.032033  0.325927 -0.089124  0.060066   \n",
      "2  0.171062 -0.006862 -0.092904  0.191909 -0.059166  0.084494  0.057149   \n",
      "3  0.091722 -0.023084 -0.170847  0.275267 -0.098605 -0.062822  0.026235   \n",
      "4  0.058596 -0.003751 -0.051466  0.243470  0.019038 -0.036104 -0.019322   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.155956  0.116585 -0.038332  ...   0.072443   0.059975  -0.076614   \n",
      "1  0.011424  0.037144 -0.126206  ...   0.060893  -0.161714  -0.016327   \n",
      "2 -0.057770  0.018334  0.042601  ...  -0.011123   0.010387   0.074528   \n",
      "3 -0.048630 -0.013406 -0.024388  ...  -0.104926   0.042281   0.022375   \n",
      "4 -0.011959 -0.054584 -0.058981  ...  -0.159260   0.032556  -0.005767   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0   0.036943   0.130576   0.409834  -0.142671   0.027263  -0.046064       0  \n",
      "1   0.029357   0.101992   0.217288  -0.190804   0.010403  -0.092698       0  \n",
      "2  -0.054416  -0.009584   0.244145  -0.002439   0.106801   0.046556       0  \n",
      "3   0.038976  -0.098919  -0.080987   0.140436   0.061884   0.038201       0  \n",
      "4   0.025254  -0.051693   0.056800  -0.031124   0.041619   0.015181       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.904e+01, tolerance: 1.953e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.433e+01, tolerance: 1.962e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.049e+01, tolerance: 1.996e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.998e+01, tolerance: 1.952e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.957e+01, tolerance: 1.913e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+01, tolerance: 1.955e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.158e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.973e+01, tolerance: 1.941e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.593e+01, tolerance: 1.957e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.073e+01, tolerance: 1.953e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.299e+01, tolerance: 1.962e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.029e+01, tolerance: 1.996e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.082e+01, tolerance: 1.952e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.016e+01, tolerance: 1.913e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.691e+01, tolerance: 1.955e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.752e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.880e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.209e+01, tolerance: 1.941e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.018e+01, tolerance: 1.957e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.604e+00, tolerance: 6.580e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.316e+00, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.752e+00, tolerance: 6.482e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.516e+00, tolerance: 6.713e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.702e+00, tolerance: 6.710e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.205e+00, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.674e+00, tolerance: 6.642e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.651e+00, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.555e+00, tolerance: 6.659e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.155e+00, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.509e+00, tolerance: 6.580e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e+01, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+01, tolerance: 6.482e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.868e+00, tolerance: 6.713e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.620e+00, tolerance: 6.710e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e+01, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.461e+00, tolerance: 6.642e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+01, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+01, tolerance: 6.659e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.849e+00, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (regularization strength): 0.01\n",
      "MSE: 0.9328511603607741\n",
      "RMSE: 0.9658422026194414\n",
      "R²: 0.33879625535420954\n",
      "Standard Deviation of MSE: 0.15535334313966961\n"
     ]
    }
   ],
   "source": [
    "'''Lasso Regression'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (assuming it's an Excel file as provided)\n",
    "df = pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "# Display basic info to ensure the data is loaded correctly\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "# Separate the features (embeddings) and target (output)\n",
    "X = df.drop(columns=['output']).values\n",
    "y = df['output'].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the Lasso Regression model\n",
    "model = Lasso()\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Grid Search for hyperparameter tuning (regularization strength 'alpha')\n",
    "grid_params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}  # You can add more values if needed\n",
    "grid_search = GridSearchCV(model, grid_params, cv=kf, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# To speed up computation, let's reduce the dataset size by sampling 500 rows\n",
    "df_sample = df.sample(n=500, random_state=42)\n",
    "X_sample = df_sample.drop(columns=['output']).values\n",
    "y_sample = df_sample['output'].values\n",
    "\n",
    "# Normalize the sample data\n",
    "X_sample_scaled = scaler.fit_transform(X_sample)\n",
    "\n",
    "# Perform Grid Search and Cross Validation on the sample\n",
    "grid_search.fit(X_sample_scaled, y_sample)\n",
    "\n",
    "# Get the best estimator for the sample\n",
    "best_model_sample = grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation\n",
    "mse_scores_sample = cross_val_score(best_model_sample, X_sample_scaled, y_sample, cv=kf, scoring='neg_mean_squared_error')\n",
    "r2_scores_sample = cross_val_score(best_model_sample, X_sample_scaled, y_sample, cv=kf, scoring='r2')\n",
    "\n",
    "# Calculate metrics for the sample\n",
    "mse_sample = -mse_scores_sample.mean()  # MSE (convert from negative MSE)\n",
    "rmse_sample = np.sqrt(mse_sample)       # RMSE\n",
    "r2_sample = r2_scores_sample.mean()     # R²\n",
    "std_dev_sample = np.std(mse_scores_sample)  # Standard deviation of MSE\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Best alpha (regularization strength): {grid_search.best_params_['alpha']}\")\n",
    "print(f\"MSE: {mse_sample}\")\n",
    "print(f\"RMSE: {rmse_sample}\")\n",
    "print(f\"R²: {r2_sample}\")\n",
    "print(f\"Standard Deviation of MSE: {std_dev_sample}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec61724-a409-4404-b8f9-06ec12651428",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b721206c-2b60-4c3b-a755-49ec248bba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.767 total time=   0.4s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.820 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.942 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-1.047 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-1.235 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.761 total time=   0.1s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.722 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.711 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.750 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.793 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.644 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.696 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.799 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.928 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-1.181 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.681 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.621 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.547 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.674 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.707 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.788 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.844 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.912 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-1.012 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-1.241 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.726 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.682 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.655 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.729 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.755 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.659 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.696 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.768 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.908 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-1.179 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.651 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.614 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.478 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.668 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.682 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.736 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.961 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-1.059 total time=   0.1s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-1.070 total time=   0.1s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-1.171 total time=   0.1s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.753 total time=   0.1s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.743 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.885 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.727 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.797 total time=   0.1s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.559 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.686 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.868 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.927 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-1.049 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.596 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.598 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.634 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.647 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.723 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.961 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-1.063 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-1.080 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-1.186 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.707 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.725 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.867 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.727 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.808 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.545 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.717 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.863 total time=   0.3s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.938 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-1.067 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.634 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.576 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.597 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.633 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.661 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.754 total time=   0.1s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-1.008 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-1.180 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-1.141 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-1.133 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.772 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.845 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.937 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.728 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.830 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.566 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.722 total time=   0.1s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.925 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.956 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.985 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.637 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.635 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.620 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.606 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.652 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.783 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-1.102 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-1.194 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-1.152 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-1.121 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.797 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.823 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.948 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.743 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.887 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.582 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.788 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.922 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.962 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.971 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.658 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.628 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.619 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.617 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.690 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.794 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-1.080 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-1.268 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-1.091 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-1.113 total time=   0.1s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.838 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.879 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.965 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.729 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.878 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.576 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.758 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.919 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.903 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.950 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.659 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.639 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.629 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.600 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.806 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-1.249 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-1.075 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.862 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.899 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.932 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.722 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.899 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.566 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.764 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.881 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.882 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.920 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.673 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.649 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.605 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.594 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.665 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.803 total time=   0.1s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.088 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.330 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.065 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.128 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.888 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.925 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.033 total time=   0.1s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.735 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.976 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.559 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.776 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.899 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.879 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.930 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.664 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.638 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.586 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.716 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.818 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.092 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.323 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.063 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.125 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.901 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.956 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.037 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.739 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.939 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.565 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.771 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.878 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.877 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.920 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.688 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.648 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.651 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.587 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.676 total time=   0.0s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.770 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.820 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.941 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-1.047 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-1.235 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.761 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.728 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.711 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.750 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.800 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.647 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.696 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.797 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.928 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-1.181 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.681 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.626 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.547 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.674 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.714 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.791 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.844 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.924 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-1.012 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-1.241 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.726 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.678 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.641 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.746 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.760 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.661 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.696 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.778 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.908 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-1.179 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.652 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.611 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.472 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.683 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.688 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.731 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.961 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.051 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.062 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.171 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.753 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.744 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.885 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.729 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.793 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.559 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.686 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.861 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.918 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-1.049 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.653 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.596 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.598 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.634 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.643 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.723 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.957 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.060 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.080 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.191 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.713 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.725 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.874 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.740 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.808 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.542 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.717 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.862 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.937 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-1.072 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.642 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.577 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.601 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.639 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.661 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.754 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.008 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.176 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.143 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.138 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.772 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.846 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.937 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.728 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.833 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.566 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.722 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.922 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.958 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.989 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.637 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.635 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.620 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.606 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.652 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.783 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.102 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.192 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.152 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.125 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.797 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.825 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.950 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.743 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.889 total time=   0.2s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.580 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.788 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.922 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.963 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.975 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.661 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.629 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.620 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.617 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.693 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.794 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.078 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.271 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.090 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.117 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.838 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.878 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.966 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.729 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.874 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.576 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.757 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.919 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.903 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.953 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.659 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.639 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.630 total time=   0.4s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.600 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.653 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.806 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.253 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.080 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.098 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.866 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.905 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.933 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.722 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.896 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.564 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.764 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.881 total time=   0.2s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.887 total time=   0.2s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.923 total time=   0.2s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.678 total time=   0.2s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.651 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.605 total time=   0.2s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.594 total time=   0.2s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.666 total time=   0.2s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.804 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.089 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.331 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.066 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.131 total time=   0.2s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.891 total time=   0.2s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.926 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.032 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.735 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.977 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.559 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.777 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.900 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.880 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.933 total time=   0.2s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.667 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.639 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.653 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.586 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.716 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.818 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.093 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.322 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.065 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.125 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.901 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.957 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.038 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.739 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.939 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.563 total time=   0.2s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.771 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.877 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.880 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.920 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.691 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.650 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.650 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.587 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.676 total time=   0.3s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.757 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.820 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.930 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-1.047 total time=   0.3s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-1.235 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.761 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.731 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.711 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.750 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.800 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.636 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.696 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.787 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.928 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-1.181 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.681 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.629 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.547 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.674 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.715 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.779 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.844 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.912 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-1.012 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-1.241 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.726 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.681 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.655 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.746 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.760 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.650 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.696 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.768 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.908 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-1.179 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.652 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.614 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.478 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.683 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.689 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.732 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.961 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.052 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.062 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.171 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.750 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.741 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.885 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.727 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.794 total time=   0.3s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.559 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.686 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.861 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.918 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-1.049 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.650 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.596 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.598 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.633 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.643 total time=   0.3s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.717 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.961 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.062 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.080 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.191 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.710 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.724 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.874 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.740 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.808 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.542 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.717 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.862 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.937 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-1.072 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.639 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.577 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.601 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.639 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.661 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.754 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.008 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.176 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.143 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.134 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.772 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.844 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.937 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.728 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.833 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.566 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.722 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.922 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.958 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.985 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.637 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.634 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.620 total time=   0.3s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.606 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.652 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.783 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.102 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.194 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.151 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.125 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.797 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.827 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.949 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.743 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.882 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.580 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.788 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.922 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.962 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.975 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.661 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.628 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.619 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.617 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.687 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.794 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.078 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.269 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.096 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.114 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.838 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.878 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.966 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.729 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.874 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.576 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.757 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.919 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.909 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.950 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.659 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.639 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.630 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.600 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.652 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.806 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.249 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.081 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.866 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.901 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.933 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.723 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.896 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.564 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.764 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.881 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.887 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.920 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.678 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.648 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.605 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.595 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.666 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.803 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.089 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.330 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.067 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.128 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.891 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.926 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.032 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.735 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.977 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.559 total time=   0.3s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.776 total time=   0.3s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.899 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.880 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.930 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.667 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.639 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.653 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.586 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.716 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.817 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.092 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.323 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.066 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.125 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.902 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.957 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.039 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.739 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.939 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.563 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.771 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.878 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.880 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.920 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.691 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.650 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.650 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.587 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.676 total time=   0.5s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.767 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.820 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.942 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-1.047 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-1.235 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.761 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.722 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.711 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.750 total time=   0.1s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.793 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.644 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.696 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.799 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.928 total time=   0.1s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-1.181 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.681 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.621 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.547 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.674 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.707 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.788 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.844 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.912 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-1.012 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-1.241 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.726 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.682 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.655 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.729 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.755 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.659 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.696 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.768 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.908 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-1.179 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.651 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.614 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.478 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.668 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.682 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.736 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.961 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-1.059 total time=   0.1s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-1.070 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-1.171 total time=   0.1s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.753 total time=   0.1s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.743 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.885 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.727 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.797 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.559 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.686 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.868 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.927 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-1.049 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.596 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.598 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.634 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.647 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.723 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.961 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-1.063 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-1.080 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-1.186 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.707 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.725 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.867 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.727 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.808 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.545 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.717 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.863 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.938 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-1.067 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.634 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.576 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.597 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.633 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.661 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.754 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-1.008 total time=   0.1s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-1.180 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-1.141 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-1.133 total time=   0.1s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.772 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.845 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.937 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.728 total time=   0.1s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.830 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.566 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.722 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.925 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.956 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.985 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.637 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.635 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.620 total time=   0.1s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.606 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.652 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.783 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-1.102 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-1.194 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-1.152 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-1.121 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.797 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.823 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.948 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.743 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.887 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.582 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.788 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.922 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.962 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.971 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.658 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.628 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.619 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.617 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.690 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.794 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-1.080 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-1.268 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-1.091 total time=   0.1s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-1.113 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.838 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.879 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.965 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.729 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.878 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.576 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.758 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.919 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.903 total time=   0.1s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.950 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.659 total time=   0.1s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.639 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.629 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.600 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.806 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-1.249 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-1.075 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.862 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.899 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.932 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.722 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.899 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.566 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.764 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.881 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.882 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.920 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.673 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.649 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.605 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.594 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.665 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.803 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.088 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.330 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.065 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.128 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.888 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.925 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.033 total time=   0.1s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.735 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.976 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.559 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.776 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.899 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.879 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.930 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.664 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.638 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.586 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.716 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.818 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.092 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.323 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.063 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.125 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.901 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.956 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.037 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.739 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.939 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.565 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.771 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.878 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.877 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.920 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.688 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.648 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.651 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.587 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.676 total time=   0.0s\n",
      "Best Parameters: {'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "Mean Squared Error (MSE) on Test Set: 0.6686\n",
      "Root Mean Squared Error (RMSE) on Test Set: 0.8177\n",
      "Standard Deviation of Predictions on Test Set: 1.0091\n",
      "R² value on Test Set: 0.5635\n",
      "Cross-Validation MSE: 1.2470 ± 1.4179\n",
      "Cross-Validation RMSE: 0.9982 ± 0.5005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset from Excel file\n",
    "data= pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "# Separate features (embeddings) and output\n",
    "X = data.drop(columns=['output'])\n",
    "y = data['output']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Set up the K-Nearest Neighbors Regressor\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Set up the grid search with 10-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Perform grid search using scaled data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_test = best_knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate MSE and RMSE on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Calculate standard deviation of predictions on the test set\n",
    "std_dev_test = np.std(y_pred_test)\n",
    "\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Mean Squared Error (MSE) on Test Set: {mse_test:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) on Test Set: {rmse_test:.4f}')\n",
    "print(f'Standard Deviation of Predictions on Test Set: {std_dev_test:.4f}')\n",
    "\n",
    "# Calculate R² value on the test set\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print(f\"R² value on Test Set: {r2_test:.4f}\")\n",
    "\n",
    "# 10-Fold Cross-Validation\n",
    "cv_scores = cross_val_score(best_knn, scaler.fit_transform(X), y, cv=10, scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.sqrt(-cv_scores)\n",
    "cv_mse = -cv_scores  # This gives you the MSE scores\n",
    "\n",
    "print(f'Cross-Validation MSE: {cv_mse.mean():.4f} ± {cv_mse.std():.4f}')\n",
    "print(f'Cross-Validation RMSE: {cv_rmse.mean():.4f} ± {cv_rmse.std():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a800c0-cb24-41cc-9170-f5b460436e45",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae31c91-8bfe-4eb3-b017-0016a1ceb2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time= 1.1min\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  58.9s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  55.1s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  55.9s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  55.2s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  47.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  48.6s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  47.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  52.3s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  51.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  58.6s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  56.6s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  54.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  50.3s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  44.2s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  44.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  55.7s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  49.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  44.6s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  44.3s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 553. GiB for an array with shape (975, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 553. GiB for an array with shape (976, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 104. TiB for an array with shape (975, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 104. TiB for an array with shape (976, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-1.53759240e+21             nan             nan -2.38968084e+21\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'linear__fit_intercept': True, 'poly__degree': 2}\n",
      "Root Mean Squared Error (RMSE) on Test Set: 77570434032.98264\n",
      "R² value on Test Set: -3.927784212579305e+21\n",
      "Standard Deviation of Predictions: 76796804149.78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset (replace 'gpt2_embeddings_input_output_custom_columns.csv' with the actual file)\n",
    "data= pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "# Separate features (embeddings) and output (marks)\n",
    "X = data.drop(columns=['output'])\n",
    "y = data['output']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with PolynomialFeatures and LinearRegression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('poly', PolynomialFeatures()),  # Polynomial features transformation\n",
    "    ('linear', LinearRegression())  # Linear regression model\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV (removed 'normalize' parameter)\n",
    "param_grid = {\n",
    "    'poly__degree': [2, 3, 4],  # Different degrees of polynomial features\n",
    "    'linear__fit_intercept': [True, False]  # Fit intercept or not\n",
    "}\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='neg_mean_squared_error', verbose=2)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "# Calculate the standard deviation of the predictions\n",
    "std_dev = np.std(y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Root Mean Squared Error (RMSE) on Test Set: {rmse}')\n",
    "print(f'R² value on Test Set: {r2}')\n",
    "print(f'Standard Deviation of Predictions: {std_dev}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3ba5a-8343-4048-a397-549fc3efd191",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b851319-8d01-411b-a0fe-e19a8d7f862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "R^2 Score:  0.352054964980268\n",
      "RMSE:  0.9963031296745293\n",
      "Cross-validated RMSE:  0.9779680670303673\n",
      "Standard Deviation of Predictions: 1.1961071190749342\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset (replace with the actual file or DataFrame)\n",
    "# Assuming the dataset is loaded as a pandas DataFrame 'df'\n",
    "df= pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "# Drop 'output' column for X, and separate it as y\n",
    "X = df.drop(columns=['output'])\n",
    "y = df['output']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets (optional for final evaluation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Grid Search for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2'],  # l2 regularization for Logistic Regression\n",
    "}\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by Grid Search\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score: \", r2)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: \", rmse)\n",
    "\n",
    "# Calculate the standard deviation of the predictions\n",
    "std_dev = np.std(y_pred)\n",
    "\n",
    "# Cross-validation RMSE\n",
    "cross_val_scores = cross_val_score(best_model, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.mean(np.sqrt(-cross_val_scores))\n",
    "print(\"Cross-validated RMSE: \", cv_rmse)\n",
    "print(f'Standard Deviation of Predictions: {std_dev}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6b43f-022a-492b-a16a-7c9bb4c30772",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eacf53e-4074-4561-927b-1c6e40373121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0 -0.002268 -0.057392 -0.051938 -0.254064 -0.107042 -0.005746  0.053339   \n",
      "1 -0.095116  0.002254 -0.080440 -0.032033  0.325927 -0.089124  0.060066   \n",
      "2  0.171062 -0.006862 -0.092904  0.191909 -0.059166  0.084494  0.057149   \n",
      "3  0.091722 -0.023084 -0.170847  0.275267 -0.098605 -0.062822  0.026235   \n",
      "4  0.058596 -0.003751 -0.051466  0.243470  0.019038 -0.036104 -0.019322   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.155956  0.116585 -0.038332  ...   0.072443   0.059975  -0.076614   \n",
      "1  0.011424  0.037144 -0.126206  ...   0.060893  -0.161714  -0.016327   \n",
      "2 -0.057770  0.018334  0.042601  ...  -0.011123   0.010387   0.074528   \n",
      "3 -0.048630 -0.013406 -0.024388  ...  -0.104926   0.042281   0.022375   \n",
      "4 -0.011959 -0.054584 -0.058981  ...  -0.159260   0.032556  -0.005767   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0   0.036943   0.130576   0.409834  -0.142671   0.027263  -0.046064       0  \n",
      "1   0.029357   0.101992   0.217288  -0.190804   0.010403  -0.092698       0  \n",
      "2  -0.054416  -0.009584   0.244145  -0.002439   0.106801   0.046556       0  \n",
      "3   0.038976  -0.098919  -0.080987   0.140436   0.061884   0.038201       0  \n",
      "4   0.025254  -0.051693   0.056800  -0.031124   0.041619   0.015181       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n",
      "MSE: 5.508192793445987e+21\n",
      "RMSE: 74217200118.61124\n",
      "R²: -3.568389584980578e+21\n",
      "Standard Deviation of MSE: 5.894379626681844e+21\n"
     ]
    }
   ],
   "source": [
    "'''Linear Regression'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (assuming it's an Excel file as provided)\n",
    "df= pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "\n",
    "# Display basic info to ensure the data is loaded correctly\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "# Separate the features (embeddings) and target (output)\n",
    "X = df.drop(columns=['output']).values\n",
    "y = df['output'].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Grid Search (though linear regression doesn't have hyperparameters, this is for extensibility)\n",
    "grid_params = {}  # No hyperparameters for basic LinearRegression\n",
    "grid_search = GridSearchCV(model, grid_params, cv=kf, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# To speed up computation, let's reduce the dataset size by sampling 500 rows\n",
    "df_sample = df.sample(n=500, random_state=42)\n",
    "X_sample = df_sample.drop(columns=['output']).values\n",
    "y_sample = df_sample['output'].values\n",
    "\n",
    "# Normalize the sample data\n",
    "X_sample_scaled = scaler.fit_transform(X_sample)\n",
    "\n",
    "# Perform Grid Search and Cross Validation on the sample\n",
    "grid_search.fit(X_sample_scaled, y_sample)\n",
    "\n",
    "# Get the best estimator for the sample\n",
    "best_model_sample = grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation\n",
    "mse_scores_sample = cross_val_score(best_model_sample, X_sample_scaled, y_sample, cv=kf, scoring='neg_mean_squared_error')\n",
    "r2_scores_sample = cross_val_score(best_model_sample, X_sample_scaled, y_sample, cv=kf, scoring='r2')\n",
    "\n",
    "# Calculate metrics for the sample\n",
    "mse_sample = -mse_scores_sample.mean()  # MSE (convert from negative MSE)\n",
    "rmse_sample = np.sqrt(mse_sample)       # RMSE\n",
    "r2_sample = r2_scores_sample.mean()     # R²\n",
    "std_dev_sample = np.std(mse_scores_sample)  # Standard deviation of MSE\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"MSE: {mse_sample}\")\n",
    "print(f\"RMSE: {rmse_sample}\")\n",
    "print(f\"R²: {r2_sample}\")\n",
    "print(f\"Standard Deviation of MSE: {std_dev_sample}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e058e-e945-47c4-8f93-8e10ee45593c",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "681b8be0-d664-444d-8623-f54a68431bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 20}\n",
      "R^2 Score: 0.27132947089194637\n",
      "RMSE: 1.0565450358948874\n",
      "MAE: 0.682410824108241\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [-0.06341399 -0.05463411  0.03253953 -0.08660526 -0.13790409]\n",
      "Cross-Validation Mean: -0.062003585403908226\n",
      "Cross-Validation Std Dev: 0.055427119347098035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [        nan  0.07130069  0.02709009 -0.04284067  0.01876929  0.01214975\n",
      "  0.00238452  0.01057024 -0.00596887         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load the dataset\n",
    "df= pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['output'])\n",
    "y = df['output']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimension reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree Regression model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Parameter tuning using RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': np.arange(2, 10),\n",
    "    'min_samples_leaf': np.arange(1, 5),\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(random_search.best_estimator_, X_train, y_train, cv=kf)\n",
    "\n",
    "# Predictions\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Performance metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mean_value = np.mean(y_test)\n",
    "std_dev = np.std(y_test)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"Mean of Output: {mean_value}\")\n",
    "print(f\"Standard Deviation of Output: {std_dev}\")\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27729928-3f9e-48de-b6b9-169d3acfb1f4",
   "metadata": {},
   "source": [
    "# Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "228f4655-e48c-4b90-8569-9de9ad20c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lambda_2': 0.0001, 'lambda_1': 0.1, 'alpha_2': 0.1, 'alpha_1': 0.001}\n",
      "R^2 Score: 0.43316623718084224\n",
      "RMSE: 0.931859134434971\n",
      "MAE: 0.7654710621707257\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [0.39647098 0.37840157 0.45102912 0.44629659 0.41795508]\n",
      "Cross-Validation Mean: 0.4180306685016288\n",
      "Cross-Validation Std Dev: 0.028011251967096144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load the dataset\n",
    "df= pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['output'])\n",
    "y = df['output']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimension reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Bayesian Ridge Regression model\n",
    "model = BayesianRidge()\n",
    "\n",
    "# Parameter tuning using RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'alpha_1': np.logspace(-6, -1, 6),\n",
    "    'alpha_2': np.logspace(-6, -1, 6),\n",
    "    'lambda_1': np.logspace(-6, -1, 6),\n",
    "    'lambda_2': np.logspace(-6, -1, 6)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(random_search.best_estimator_, X_train, y_train, cv=kf)\n",
    "\n",
    "# Predictions\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "# Performance metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mean_value = np.mean(y_test)\n",
    "std_dev = np.std(y_test)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"Mean of Output: {mean_value}\")\n",
    "print(f\"Standard Deviation of Output: {std_dev}\")\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23064eec-3ce6-437c-a088-e80edafcc052",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7efc220f-b1b5-4aa3-8666-0050b8a74c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None, 'bootstrap': True}\n",
      "R^2 Score: 0.5354746999113791\n",
      "RMSE: 0.8435815984811348\n",
      "MAE: 0.6583421484214842\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [0.46013964 0.49983669 0.44386573]\n",
      "Cross-Validation Mean: 0.46794735299501705\n",
      "Cross-Validation Std Dev: 0.023507547769574297\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load the dataset\n",
    "df= pd.read_csv('roberta_embeddings_input_output_custom_columns.csv')\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['output'])\n",
    "y = df['output']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimension reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Regression model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Parameter tuning using RandomizedSearchCV with fewer options\n",
    "param_dist = {\n",
    "    'n_estimators': [10, 50],  # Reduced number of estimators\n",
    "    'max_depth': [None, 10],  # Reduced max_depth options\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]  # Keeping only one option for bootstrap\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=5, cv=3, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)  # Reduced folds\n",
    "cv_scores = cross_val_score(random_search.best_estimator_, X_train, y_train, cv=kf)\n",
    "\n",
    "# Predictions\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Performance metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mean_value = np.mean(y_test)\n",
    "std_dev = np.std(y_test)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"Mean of Output: {mean_value}\")\n",
    "print(f\"Standard Deviation of Output: {std_dev}\")\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2172f6-bb35-4935-8449-5fed94a4efdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
